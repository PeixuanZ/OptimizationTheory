<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Optimization Theory Notes</title>
  <!-- MathJax for LaTeX rendering -->
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>
<body>
  <h1>Optimization Theory Notes</h1>
  <p>Welcome to my optimization notes.</p>

  <h2>Gradient Descent</h2>
  <p>
    Gradient Descent is an optimization algorithm that can be used to minimize a function. Here's a simple example:
  </p>
  <p>
    $$ f(x) = x^2 $$
  </p>
  <p>
    The update rule for gradient descent is:
  </p>
  <p>
    $$ x_{new} = x - \alpha \nabla f(x) $$
  </p>
</body>
</html>
